{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VinayChavan2006/EE655-Computer-Vision-and-Deep-Learning/blob/main/Assignment-2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import libraries\n",
        "import numpy as np\n",
        "import torch\n",
        "from torchvision import datasets\n",
        "\n",
        "# Load MNIST\n",
        "mnist_train = datasets.MNIST(root='data', train=True, download=True)\n",
        "mnist_test = datasets.MNIST(root='data', train=False, download=True)\n",
        "\n",
        "images_train = mnist_train.data.numpy()  # Shape: (60000, 28, 28)\n",
        "images_test = mnist_test.data.numpy()    # Shape: (10000, 28, 28)\n",
        "labels_train = mnist_train.targets.numpy()\n",
        "labels_test = mnist_test.targets.numpy()\n"
      ],
      "metadata": {
        "id": "rtmNBfjy5lHi"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "os.makedirs(\"./data/masks/train\", exist_ok=True)\n",
        "os.makedirs(\"./data/masks/test\", exist_ok=True)\n",
        "\n",
        "# Function to apply Otsu thresholding and create masks\n",
        "def apply_otsu_threshold(image):\n",
        "    # Apply Otsu thresholding\n",
        "    _, mask = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "    return (mask/255).astype(np.uint8)\n",
        "\n",
        "# Apply Otsu thresholding to each image and save masks\n",
        "idx = 0\n",
        "masks_train = []\n",
        "masks_test = []\n",
        "for image,label in zip(images_train,labels_train):\n",
        "  # apply otsu algo\n",
        "  res_image = (apply_otsu_threshold(image))\n",
        "  masks_train.append(res_image * 255)\n",
        "  cv2.imwrite(os.path.join(\"./data/masks/train/\",f\"{idx}.png\"),res_image)\n",
        "  idx += 1\n",
        "idx = 0\n",
        "for image,label in zip(images_test,labels_test):\n",
        "  # apply otsu algo\n",
        "  res_image = (apply_otsu_threshold(image))\n",
        "  masks_test.append(res_image * 255)\n",
        "  cv2.imwrite(os.path.join(\"./data/masks/test/\",f\"{idx}.png\"),res_image)\n",
        "  idx += 1\n",
        "\n",
        "masks_train = np.array(masks_train,dtype=np.uint8)\n",
        "masks_test = np.array(masks_test,dtype=np.uint8)"
      ],
      "metadata": {
        "id": "adxqAxyK6dA8"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(masks_train)\n",
        "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    if i < 5:\n",
        "        ax.imshow(images_train[i], cmap='gray')\n",
        "        ax.set_title(f\"Image {i}\")\n",
        "    else:\n",
        "        ax.imshow(masks_train[i-5], cmap='gray')\n",
        "        ax.set_title(f\"Mask {i-5}\")\n",
        "    ax.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "P0GAaSZXnIDH",
        "outputId": "dd243252-7589-43a3-fd7f-a76ed6d69fb2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  ...\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]]\n",
            "\n",
            " [[0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  ...\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]]\n",
            "\n",
            " [[0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  ...\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  ...\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]]\n",
            "\n",
            " [[0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  ...\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]]\n",
            "\n",
            " [[0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  ...\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x600 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tight Ground Truth Circles\n",
        "def get_tight_circles_images(img_mask):\n",
        "    # Convert the image to grayscale\n",
        "    gray = cv2.cvtColor(img_mask, cv2.COLOR_BGR2GRAY)\n",
        "    # get all contours\n",
        "    contours, _ = cv2.findContours(gray, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    # get the tight circle for each\n",
        "    if len(contours) > 0:\n",
        "        # Find the contour with the largest area\n",
        "        largest_contour = max(contours, key=cv2.contourArea)\n",
        "        # fit a circle\n",
        "        (x,y),radius = cv2.minEnclosingCircle(largest_contour)\n",
        "        # Convert the circle parameters to integers\n",
        "        center = (int(x), int(y))\n",
        "        radius = int(radius)\n",
        "        # Draw a circle with these parameters\n",
        "        cv2.circle(img_mask, center, radius, (0,255,0),2)\n",
        "        return img_mask,center,radius\n",
        "    else:\n",
        "        return None,None,None\n",
        "circle_train_images = []\n",
        "circle_test_images = []\n",
        "circle_train = []\n",
        "circle_test = []\n",
        "os.makedirs(\"./data/mnist_circles/train/\",exist_ok=True)\n",
        "os.makedirs(\"./data/mnist_circles/test/\",exist_ok=True)\n",
        "\n",
        "for i in range(len(images_train)):\n",
        "    img = cv2.imread(f\"./data/masks/train/{i}.png\") * 255\n",
        "    circ_img,center,radius = get_tight_circles_images(img)\n",
        "    circle_train_images.append(circ_img)\n",
        "    circle_train.append([center,radius])\n",
        "    cv2.imwrite(f\"./data/mnist_circles/train/{i}.png\",circ_img)\n",
        "\n",
        "for i in range(len(images_test)):\n",
        "    img = cv2.imread(f\"./data/masks/test/{i}.png\") * 255\n",
        "    circ_img,center,radius = get_tight_circles_images(img)\n",
        "    circle_test_images.append(circ_img)\n",
        "    circle_test.append([center,radius])\n",
        "    cv2.imwrite(f\"./data/mnist_circles/test/{i}.png\",circ_img)\n",
        "\n",
        "circle_train_images = np.array(circle_train_images,dtype=np.uint8)\n",
        "circle_test_images = np.array(circle_test_images,dtype=np.uint8)\n",
        "print(len(circle_train))\n",
        "circle_train = np.array(circle_train,dtype=np.float32)\n",
        "circle_test = np.array(circle_test,dtype=np.float32)\n"
      ],
      "metadata": {
        "id": "uOV7bJyymS0D",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "650882fd-39bb-4c27-f224-ac61bd49927f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60000\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (60000, 2) + inhomogeneous part.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-95062a43846b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0mcircle_test_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcircle_test_images\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcircle_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0mcircle_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcircle_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0mcircle_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcircle_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (60000, 2) + inhomogeneous part."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    if i < 5:\n",
        "        ax.imshow(masks_train[i], cmap='gray')\n",
        "        ax.set_title(f\"Image {i}\")\n",
        "    else:\n",
        "        ax.imshow(circle_train_images[i-5], cmap='gray')\n",
        "        ax.set_title(f\"Mask {i-5}\")\n",
        "    ax.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "id": "j8GZ7oFlqIc3",
        "outputId": "78b50be0-46d3-480c-d897-04df694c84f0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x600 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to concatenate 4 images and masks\n",
        "def create_concatenated_dataset(images, masks, labels, num_samples):\n",
        "    \"\"\"\n",
        "    Create a dataset by concatenating 4 images/masks in a 2x2 grid.\n",
        "    Args:\n",
        "        images: (N, 28, 28), uint8\n",
        "        masks: (N, 28, 28), float32 (0/1)\n",
        "        labels: (N,), int64 (0-9)\n",
        "        num_samples: Number of new samples to generate\n",
        "    Returns:\n",
        "        new_images: (num_samples, 56, 56), uint8\n",
        "        new_masks: (num_samples, 56, 56), int64 (0-10, background=0)\n",
        "        new_masks_onehot: (num_samples, 11, 56, 56), float32\n",
        "    \"\"\"\n",
        "    new_images = []\n",
        "    new_masks = []\n",
        "    num_images = len(images)\n",
        "\n",
        "    for _ in range(num_samples):\n",
        "        # Randomly select 4 indices\n",
        "        idx = np.random.choice(num_images, 4, replace=False)\n",
        "        img1, img2, img3, img4 = images[idx]\n",
        "        mask1, mask2, mask3, mask4 = masks[idx]\n",
        "        label1, label2, label3, label4 = labels[idx]\n",
        "\n",
        "        # Concatenate images (56x56)\n",
        "        top = np.hstack([img1, img2])\n",
        "        bottom = np.hstack([img3, img4])\n",
        "        new_img = np.vstack([top, bottom])\n",
        "\n",
        "        # Create semantic mask (0 for background, 1-10 for digits)\n",
        "        new_mask = np.zeros((56, 56), dtype=np.int64)\n",
        "        # Assign class labels (label + 1 to reserve 0 for background)\n",
        "        new_mask[:28, :28] = mask1 * (label1 + 1)\n",
        "        new_mask[:28, 28:] = mask2 * (label2 + 1)\n",
        "        new_mask[28:, :28] = mask3 * (label3 + 1)\n",
        "        new_mask[28:, 28:] = mask4 * (label4 + 1)\n",
        "\n",
        "        new_images.append(new_img)\n",
        "        new_masks.append(new_mask)\n",
        "\n",
        "    new_images = np.array(new_images)\n",
        "    new_masks = np.array(new_masks)\n",
        "\n",
        "    # One-hot encode masks\n",
        "    new_masks_onehot = np.zeros((num_samples, 11, 56, 56), dtype=np.float32)\n",
        "    for i in range(num_samples):\n",
        "        for c in range(11):\n",
        "            new_masks_onehot[i, c] = (new_masks[i] == c).astype(np.float32)\n",
        "\n",
        "    return new_images, new_masks, new_masks_onehot\n",
        "\n",
        "# Generate datasets\n",
        "num_train_samples = 60000  # Arbitrary, can match 60000 if needed\n",
        "num_test_samples = 10000    # Arbitrary, can match 10000\n",
        "train_images_2x2, train_masks_2x2, train_masks_onehot = create_concatenated_dataset(\n",
        "    images_train, masks_train, labels_train, num_train_samples\n",
        ")\n",
        "test_images_2x2, test_masks_2x2, test_masks_onehot = create_concatenated_dataset(\n",
        "    images_test, masks_test, labels_test, num_test_samples\n",
        ")\n",
        "\n",
        "# Save datasets (optional)\n",
        "# np.save(\"./data/train_images_2x2.npy\", train_images_2x2)\n",
        "# np.save(\"./data/train_masks_onehot.npy\", train_masks_onehot)\n",
        "# np.save(\"./data/test_images_2x2.npy\", test_images_2x2)\n",
        "# np.save(\"./data/test_masks_onehot.npy\", test_masks_onehot)\n",
        "\n",
        "# Verify shapes\n",
        "print(f\"Train images shape: {train_images_2x2.shape}, dtype: {train_images_2x2.dtype}\")\n",
        "print(f\"Train masks shape: {train_masks_2x2.shape}, dtype: {train_masks_2x2.dtype}\")\n",
        "print(f\"Train masks one-hot shape: {train_masks_onehot.shape}, dtype: {train_masks_onehot.dtype}\")\n",
        "print(f\"Test images shape: {test_images_2x2.shape}, dtype: {test_images_2x2.dtype}\")\n",
        "print(f\"Test masks shape: {test_masks_2x2.shape}, dtype: {test_masks_2x2.dtype}\")\n",
        "print(f\"Test masks one-hot shape: {test_masks_onehot.shape}, dtype: {test_masks_onehot.dtype}\")\n",
        "\n",
        "# Visualize a sample\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
        "axes[0].imshow(train_images_2x2[0], cmap='gray')\n",
        "axes[0].set_title(\"Concatenated Image\")\n",
        "axes[0].axis('off')\n",
        "\n",
        "# Show the class mask (non-one-hot for visualization)\n",
        "axes[1].imshow(train_masks_2x2[0], cmap='tab10')\n",
        "axes[1].set_title(\"Semantic Mask\")\n",
        "axes[1].axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "M02OiTB_y7Eb"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Question - 2\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "print(torch.cuda.is_available())  # Should return True if GPU is accessible\n",
        "\n",
        "# Custom Dataset\n",
        "class SegmentationDataset(Dataset):\n",
        "    def __init__(self, images, masks):\n",
        "        self.images = images.astype(np.float32) / 255.0\n",
        "        self.masks = masks.astype(np.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return torch.tensor(self.images[idx]).unsqueeze(0), torch.tensor(self.masks[idx]).unsqueeze(0)\n",
        "\n",
        "# Model\n",
        "class SegmentationNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SegmentationNet, self).__init__()\n",
        "        self.enc1 = nn.Conv2d(1, 32, 3, padding=1)\n",
        "        self.enc2 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "        self.dec1 = nn.Conv2d(64, 32, 3, padding=1)\n",
        "        self.dec2 = nn.Conv2d(32, 1, 3, padding=1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.relu(self.enc1(x))\n",
        "        x2 = self.pool(self.relu(self.enc2(x1)))\n",
        "        x = self.up(x2)\n",
        "        x = self.relu(self.dec1(x))\n",
        "        x = self.sigmoid(self.dec2(x))\n",
        "        return x\n",
        "\n",
        "# IoU\n",
        "def calculate_iou(pred, target, threshold=0.5):\n",
        "    pred = (pred > threshold).float()\n",
        "    intersection = (pred * target).sum()\n",
        "    union = (pred + target).sum() - intersection\n",
        "    return (intersection + 1e-6) / (union + 1e-6)\n",
        "\n",
        "# Data Loaders\n",
        "train_dataset = SegmentationDataset(images_train, masks_train)\n",
        "test_dataset = SegmentationDataset(images_test, masks_test)\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64)\n",
        "\n",
        "# Training\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = SegmentationNet()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "for epoch in range(10):\n",
        "    model.train()\n",
        "    running_loss = 0\n",
        "    for images, masks in train_loader:\n",
        "        images, masks = images, masks\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, masks)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    print(f'Epoch {epoch+1}, Loss: {running_loss / len(train_loader)}')\n",
        "\n",
        "# Evaluation\n",
        "model.eval()\n",
        "total_iou = 0\n",
        "with torch.no_grad():\n",
        "    for images, masks in test_loader:\n",
        "        images, masks = images.to(device), masks.to(device)\n",
        "        outputs = model(images)\n",
        "        total_iou += calculate_iou(outputs, masks).item()\n",
        "print(f'Test IoU: {total_iou / len(test_loader)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "FqvLv44i295U",
        "outputId": "075718ed-c792-40d5-d2d6-8132ac45b6db"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "all elements of target should be between 0 and 1",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-37d36dd71f13>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    697\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m         return F.binary_cross_entropy(\n\u001b[0m\u001b[1;32m    700\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3567\u001b[0m         \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3568\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3569\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction_enum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: all elements of target should be between 0 and 1"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Custom Dataset\n",
        "class CircleDataset(Dataset):\n",
        "    def __init__(self, images, circles):\n",
        "        self.images = images.astype(np.float32) / 255.0\n",
        "        self.circles = circles.astype(np.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return torch.tensor(self.images[idx]).unsqueeze(0), torch.tensor(self.circles[idx])\n",
        "\n",
        "# Model\n",
        "class CircleNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CircleNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
        "        self.fc_class = nn.Linear(128, 10)\n",
        "        self.fc_reg = nn.Linear(128, 3)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.pool(self.conv1(x)))\n",
        "        x = self.relu(self.pool(self.conv2(x)))\n",
        "        x = x.view(-1, 64 * 7 * 7)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        class_out = self.fc_class(x)\n",
        "        reg_out = self.fc_reg(x)\n",
        "        return class_out, reg_out\n",
        "\n",
        "# Circle IoU\n",
        "def circle_iou(pred, gt):\n",
        "    x1, y1, r1 = pred\n",
        "    x2, y2, r2 = gt\n",
        "    d = ((x1 - x2)**2 + (y1 - y2)**2)**0.5\n",
        "    if d >= r1 + r2:\n",
        "        return 0.0\n",
        "    if d <= abs(r1 - r2):\n",
        "        return 1.0 if r1 < r2 else (r1 / r2)**2\n",
        "    # Approximate intersection\n",
        "    a = r1**2 * np.arccos((d**2 + r1**2 - r2**2) / (2 * d * r1 + 1e-6))\n",
        "    b = r2**2 * np.arccos((d**2 + r2**2 - r1**2) / (2 * d * r2 + 1e-6))\n",
        "    c = 0.5 * ((r1 + r2 - d) * (d + r1 - r2) * (d + r2 - r1) * (d + r1 + r2))**0.5\n",
        "    intersection = a + b - c\n",
        "    union = np.pi * (r1**2 + r2**2) - intersection\n",
        "    return intersection / (union + 1e-6)\n",
        "\n",
        "# Data Loaders\n",
        "train_dataset = CircleDataset(images_train, circles_train)\n",
        "test_dataset = CircleDataset(images_test, circles_test)\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64)\n",
        "\n",
        "# Training\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = CircleNet().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "class_criterion = nn.CrossEntropyLoss()\n",
        "reg_criterion = nn.MSELoss()\n",
        "\n",
        "for epoch in range(10):\n",
        "    model.train()\n",
        "    running_loss = 0\n",
        "    for images, circles in train_loader:\n",
        "        images, circles = images.to(device), circles.to(device)\n",
        "        labels = circles[:, 3].long()\n",
        "        circle_params = circles[:, :3]\n",
        "        optimizer.zero_grad()\n",
        "        class_out, reg_out = model(images)\n",
        "        class_loss = class_criterion(class_out, labels)\n",
        "        reg_loss = reg_criterion(reg_out, circle_params)\n",
        "        loss = class_loss + reg_loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    print(f'Epoch {epoch+1}, Loss: {running_loss / len(train_loader)}')\n",
        "\n",
        "# Evaluation\n",
        "model.eval()\n",
        "total_iou = 0\n",
        "num_samples = 0\n",
        "with torch.no_grad():\n",
        "    for images, circles in test_loader:\n",
        "        images, circles = images.to(device), circles.to(device)\n",
        "        labels = circles[:, 3].long()\n",
        "        class_out, reg_out = model(images)\n",
        "        pred_labels = torch.argmax(class_out, dim=1)\n",
        "        for i in range(len(pred_labels)):\n",
        "            if pred_labels[i] == labels[i]:\n",
        "                total_iou += circle_iou(reg_out[i].cpu().numpy(), circles[i, :3].cpu().numpy())\n",
        "            num_samples += 1\n",
        "print(f'Test IoU: {total_iou / num_samples}')"
      ],
      "metadata": {
        "id": "KCfhBF_Y7z2w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Custom Dataset\n",
        "class SemanticDataset(Dataset):\n",
        "    def __init__(self, images, masks):\n",
        "        self.images = images.astype(np.float32) / 255.0\n",
        "        self.masks = masks.astype(np.int64)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return torch.tensor(self.images[idx]).unsqueeze(0), torch.tensor(self.masks[idx])\n",
        "\n",
        "# Model\n",
        "class SemanticNet(nn.Module):\n",
        "    def __init__(self, num_classes=11):\n",
        "        super(SemanticNet, self).__init__()\n",
        "        self.enc1 = nn.Conv2d(1, 32, 3, padding=1)\n",
        "        self.enc2 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "        self.dec1 = nn.Conv2d(64, 32, 3, padding=1)\n",
        "        self.dec2 = nn.Conv2d(32, num_classes, 3, padding=1)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.relu(self.enc1(x))\n",
        "        x2 = self.pool(self.relu(self.enc2(x1)))\n",
        "        x = self.up(x2)\n",
        "        x = self.relu(self.dec1(x))\n",
        "        x = self.dec2(x)\n",
        "        return x\n",
        "\n",
        "# Dice Coefficient\n",
        "def calculate_dice(pred, target):\n",
        "    pred = torch.argmax(pred, dim=1)\n",
        "    dice = 0\n",
        "    for c in range(11):\n",
        "        p = (pred == c).float()\n",
        "        t = (target == c).float()\n",
        "        intersection = (p * t).sum()\n",
        "        dice += (2 * intersection + 1e-6) / (p.sum() + t.sum() + 1e-6)\n",
        "    return dice / 11\n",
        "\n",
        "# Data Loaders\n",
        "train_dataset = SemanticDataset(seg_images_train, seg_masks_train)\n",
        "test_dataset = SemanticDataset(seg_images_test, seg_masks_test)\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16)\n",
        "\n",
        "# Training\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = SemanticNet().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "for epoch in range(10):\n",
        "    model.train()\n",
        "    running_loss = 0\n",
        "    for images, masks in train_loader:\n",
        "        images, masks = images.to(device), masks.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, masks)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    print(f'Epoch {epoch+1}, Loss: {running_loss / len(train_loader)}')\n",
        "\n",
        "# Evaluation\n",
        "model.eval()\n",
        "total_dice = 0\n",
        "with torch.no_grad():\n",
        "    for images, masks in test_loader:\n",
        "        images, masks = images.to(device), masks.to(device)\n",
        "        outputs = model(images)\n",
        "        total_dice += calculate_dice(outputs, masks).item()\n",
        "print(f'Test Dice: {total_dice / len(test_loader)}')"
      ],
      "metadata": {
        "id": "Fw5o35zI7-e8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# video background subtraction\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "video = cv2.VideoCapture(r\"C:\\Users\\vinay\\OneDrive\\Desktop\\courses\\Sem-4\\EE655\\q5_18a4ee81-96e1-4415-94a6-c8e9521bce78\\q5\\denis_walk.avi\")\n",
        "bg_image = cv2.imread(r\"C:\\Users\\vinay\\OneDrive\\Desktop\\courses\\Sem-4\\EE655\\q5_18a4ee81-96e1-4415-94a6-c8e9521bce78\\q5\\bg.png\")\n",
        "\n",
        "frames = []\n",
        "\n",
        "while True:\n",
        "    ret, frame = video.read()\n",
        "\n",
        "    if not ret:\n",
        "        break\n",
        "    # frame = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
        "    frames.append(frame)\n",
        "\n",
        "\n",
        "initialFrame = frames[0]\n",
        "\n",
        "def averageFrame(frames):\n",
        "    add_frame = np.zeros(np.shape(frames[0]))\n",
        "    for i in range(len(frames)):\n",
        "        add_frame = add_frame + frames[i]\n",
        "    return ((add_frame)/len(frames))\n",
        "\n",
        "avg_frame = np.array(averageFrame(frames),dtype=np.uint8)\n",
        "\n",
        "for i in range(len(frames)):\n",
        "    # frame difference\n",
        "    # cv2.imshow(\"vid1\",frames[i+1] - frames[i])\n",
        "\n",
        "    # frame - avg. frame\n",
        "    # print(avg_frame)\n",
        "    abs_mat = abs(frames[i] - avg_frame)\n",
        "    # Convert difference to grayscale\n",
        "    gray = cv2.cvtColor(abs_mat, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Apply Otsu's thresholding\n",
        "    _, otsu_threshold = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "\n",
        "\n",
        "    new_vid_frame = np.zeros_like(frames[i])\n",
        "    for j in range(frames[0].shape[0]):\n",
        "        for k in range(frames[0].shape[1]):\n",
        "            if otsu_threshold[j,k] == 255:\n",
        "                new_vid_frame[j,k] = frames[i][j,k]\n",
        "            else:\n",
        "                new_vid_frame[j,k] = bg_image[j,k]\n",
        "\n",
        "    cv2.imshow(\"video\",new_vid_frame)\n",
        "\n",
        "    # frame - initial frame\n",
        "    # cv2.imshow(\"vid3\", frames[i+1] - initialFrame)\n",
        "\n",
        "    cv2.waitKey(40)\n",
        "\n",
        "video.release()\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "LlEvz5de8Opd"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}